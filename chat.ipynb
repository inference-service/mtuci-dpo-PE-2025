{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5cc26-856b-4167-8267-438639a3b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало чата:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Как мне написать интерфейс для чата с LLM на ipywidgets?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YaGPT> Для создания интерфейса чата с LLM на ipywidgets вам потребуется выполнить следующие шаги:\n",
      "\n",
      "1. **Импортировать необходимые модули:**\n",
      "   ```\n",
      "   import ipywidgets as widgets\n",
      "   from IPython.display import display\n",
      "   ```\n",
      "\n",
      "2. **Создать виджет ввода текста для пользователя:**\n",
      "   ```\n",
      "   user_input = widgets.TextInput(placeholder='Введите ваш вопрос или сообщение')\n",
      "   display(user_input)\n",
      "   ```\n",
      "\n",
      "3. **Создать кнопку для отправки сообщения:**\n",
      "   ```\n",
      "   send_button = widgets.Button(description='Отправить')\n",
      "   display(send_button)\n",
      "   ```\n",
      "\n",
      "4. **Добавить обработчик события для кнопки:**\n",
      "   ```\n",
      "   def on_send_button_click(button):\n",
      "       # Получаем текст из виджета ввода\n",
      "       message = user_input.value\n",
      "       # Отправляем сообщение LLM\n",
      "       # ... ваш код для отправки сообщения LLM ...\n",
      "   ```\n",
      "\n",
      "5. **Подключить обработчик к кнопке:**\n",
      "   ```\n",
      "   send_button.on_click(on_send_button_click)\n",
      "   ```\n",
      "\n",
      "6. **Создать виджет для отображения ответа от LLM:**\n",
      "   ```\n",
      "   llms_response = widgets.Textarea(placeholder='Ответ от LLM')\n",
      "   display(llms_response)\n",
      "   ```\n",
      "\n",
      "7. **Обновить виджет с ответом при получении ответа от LLM:**\n",
      "   ```\n",
      "   def update_response(response):\n",
      "       llms_response.value = response\n",
      "   ```\n",
      "\n",
      "8. **Настроить цикл получения ответов от LLM:**\n",
      "   ```\n",
      "   # Ваш код для получения ответов от LLM здесь\n",
      "   while True:\n",
      "       response = get_llm_response()\n",
      "       update_response(response)\n",
      "   time.sleep(1)\n",
      "   ```\n",
      "\n",
      "Это базовый пример, который можно расширить и настроить под ваши конкретные потребности. Например, вы можете добавить возможность выбора модели LLM, настройку параметров запроса и т. д.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from yandex_cloud_ml_sdk import YCloudML\n",
    "from yandex_cloud_ml_sdk.auth import IAMTokenAuth\n",
    "\n",
    "import dotenv, os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "config = dotenv.dotenv_values()\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"text\": \"Ты программист Python, хорошо знающий ipywidgets\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def main():\n",
    "    sdk = YCloudML(\n",
    "        folder_id=config[\"FOLDER_ID\"],\n",
    "        auth=IAMTokenAuth(config[\"YC_IAM_TOKEN\"]),\n",
    "        enable_server_data_logging=False,\n",
    "    )\n",
    "    model = sdk.models.completions(\"yandexgpt-lite\").configure(temperature=0.6)\n",
    "    print(\"Начало чата:\")\n",
    "\n",
    "    msg_text = input(\"> \")\n",
    "    if msg_text.lower() == \"exit\":\n",
    "            return\n",
    "    messages.append({\"role\": \"user\", \"text\": msg_text})\n",
    "    result = (\n",
    "        model.run(messages)\n",
    "    )\n",
    "\n",
    "\n",
    "    for alternative in result:\n",
    "        print(f\"YaGPT> {alternative.text}\")\n",
    "\n",
    "    while True:\n",
    "        msg_text = input(\"> \")\n",
    "        if msg_text.lower() == \"exit\":\n",
    "            return\n",
    "        messages.append({\"role\": \"user\", \"text\": msg_text})\n",
    "        result = (\n",
    "            model.run(messages)\n",
    "        )\n",
    "        messages.append({\"role\": result.role, \"text\": result.text})\n",
    "        print(f\"YaGPT> {result.text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b5e23-f294-44cb-affe-1699afe579d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Потоковая генерация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7f83fd-3393-42ae-9a48-d931a98e7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative(role='assistant', text='О', status=<AlternativeStatus.PARTIAL: 1>, tool_calls=None)\n",
      "Alternative(role='assistant', text='Ошибки сами себя не исправляют.', status=<AlternativeStatus.FINAL: 3>, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from yandex_cloud_ml_sdk import YCloudML\n",
    "from yandex_cloud_ml_sdk.auth import IAMTokenAuth\n",
    "\n",
    "import dotenv, os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "config = dotenv.dotenv_values()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"text\": \"Найди ошибки в тексте и исправь их\"},\n",
    "    {\"role\": \"user\", \"text\": \"Ашипки саме сибя ни исрпвят.\"},\n",
    "    {\"role\":\"assistant\",\"text\":\"Ошибки сами себя не исправят.\"},\n",
    "]\n",
    "\n",
    "\n",
    "def main():\n",
    "    sdk = YCloudML(\n",
    "        folder_id=config[\"FOLDER_ID\"],\n",
    "        auth=IAMTokenAuth(config[\"YC_IAM_TOKEN\"]),\n",
    "        enable_server_data_logging=False,\n",
    "    )\n",
    "\n",
    "    model = sdk.models.completions(\"yandexgpt-lite\")\n",
    "\n",
    "    \n",
    "    for result in model.configure(temperature=0.5).run_stream(messages):\n",
    "        for alternative in result:\n",
    "            print(alternative)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e1a57-1262-4e9f-93f8-a8053a525e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Асинхронная генерация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc6c4fa-a16c-4013-a565-12eb1dd36b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 1:\n",
      "GPTModelResult(alternatives=(Alternative(role='assistant', text='Ламинат подойдёт для укладки на кухне или в детской комнате — он не боится влаги и механических повреждений благодаря защитному слою из облицованных меламиновых плёнок толщиной 0,2 мм и обработанным воском замкам.', status=<AlternativeStatus.FINAL: 3>, tool_calls=None),), usage=CompletionUsage(input_text_tokens=74, completion_tokens=46, total_tokens=120, reasoning_tokens=0), model_version='23.10.2024')\n",
      "Variant 2:\n",
      "GPTModelResult(alternatives=(Alternative(role='assistant', text='Ошибки сами себя не исправят.', status=<AlternativeStatus.FINAL: 3>, tool_calls=None),), usage=CompletionUsage(input_text_tokens=32, completion_tokens=8, total_tokens=40, reasoning_tokens=0), model_version='23.10.2024')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import time\n",
    "from yandex_cloud_ml_sdk import YCloudML\n",
    "from yandex_cloud_ml_sdk.auth import IAMTokenAuth\n",
    "\n",
    "import dotenv, os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "config = dotenv.dotenv_values()\n",
    "\n",
    "messages_1 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"text\": \"Найди ошибки в тексте и исправь их\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"text\": \"\"\"Ламинат подойдет для укладке на кухне или в детской \n",
    "комнате – он не боиться влаги и механических повреждений благодаря \n",
    "защитному слою из облицованных меламиновых пленок толщиной 0,2 мм и \n",
    "обработанным воском замкам.\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "messages_2 = [\n",
    "    {\"role\": \"system\", \"text\": \"Найди ошибки в тексте и исправь их\"},\n",
    "    {\"role\": \"user\", \"text\": \"Ашипки саме сибя ни исрпвят.\"},\n",
    "]\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    sdk = YCloudML(\n",
    "        folder_id=config[\"FOLDER_ID\"],\n",
    "        auth=IAMTokenAuth(config[\"YC_IAM_TOKEN\"]),\n",
    "        enable_server_data_logging=False,\n",
    "    )\n",
    "\n",
    "    model = sdk.models.completions(\"yandexgpt-lite\")\n",
    "\n",
    "    # Variant 1: подождать выполнения операции, используя 5мс периоды time.sleep(5)\n",
    "\n",
    "    print(\"Variant 1:\")\n",
    "\n",
    "    operation = model.configure(temperature=0.5).run_deferred(messages_1)\n",
    "\n",
    "    status = operation.get_status()\n",
    "    while status.is_running:\n",
    "        time.sleep(5)\n",
    "        status = operation.get_status()\n",
    "\n",
    "    result = operation.get_result()\n",
    "    print(result)\n",
    "\n",
    "    # Variant 2: подождать выполнения операции через метод wait()\n",
    "\n",
    "    print(\"Variant 2:\")\n",
    "\n",
    "    operation = model.run_deferred(messages_2)\n",
    "\n",
    "    result = operation.wait()\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f1c7d-93f9-4dc2-bb82-c0a1d9d57979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
